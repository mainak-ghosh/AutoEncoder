{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras import regularizers\n",
    "from keras.callbacks import History\n",
    "history = History()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Acuisition\n",
    "x_train=pd.read_csv(\"mnist_train.csv\")\n",
    "x_test=pd.read_csv(\"mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Visulization\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "y_train = x_train.iloc[:,1].values\n",
    "x_train = x_train.drop([\"label\"],axis=1)\n",
    "y_test = x_test.iloc[:,1].values\n",
    "x_test = x_test.drop([\"label\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val= train_test_split(x_train,y_train,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape = (48000, 784)\n",
      "x_test shape = (10000, 784)\n",
      "x_val shape = (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train shape = {x_train.shape}')\n",
    "print(f'x_test shape = {x_test.shape}')\n",
    "print(f'x_val shape = {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 32\n",
    "input_img = Input(shape=(784,))\n",
    "# add a Dense layer with a L1 activity regularizer\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(32, activation='relu', activity_regularizer=regularizers.l1(1e-6))(encoded)\n",
    "decoded = Dense(128,activation='relu')(encoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 784)               101136    \n",
      "=================================================================\n",
      "Total params: 209,968\n",
      "Trainable params: 209,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss = 'binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/300\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.3529 - val_loss: 0.2778\n",
      "Epoch 2/300\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.2705 - val_loss: 0.2625\n",
      "Epoch 3/300\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.2539 - val_loss: 0.2455\n",
      "Epoch 4/300\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.2355 - val_loss: 0.2256\n",
      "Epoch 5/300\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.2186 - val_loss: 0.2125\n",
      "Epoch 6/300\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.2077 - val_loss: 0.2033\n",
      "Epoch 7/300\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.1991 - val_loss: 0.1952\n",
      "Epoch 8/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1921 - val_loss: 0.1894\n",
      "Epoch 9/300\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 0.1874 - val_loss: 0.1854\n",
      "Epoch 10/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1834 - val_loss: 0.1814\n",
      "Epoch 11/300\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1793 - val_loss: 0.1771\n",
      "Epoch 12/300\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1749 - val_loss: 0.1729\n",
      "Epoch 13/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1710 - val_loss: 0.1694\n",
      "Epoch 14/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1679 - val_loss: 0.1668\n",
      "Epoch 15/300\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1655 - val_loss: 0.1646\n",
      "Epoch 16/300\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1636 - val_loss: 0.1636\n",
      "Epoch 17/300\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1615 - val_loss: 0.1604\n",
      "Epoch 18/300\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1598 - val_loss: 0.1592\n",
      "Epoch 19/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1581 - val_loss: 0.1571\n",
      "Epoch 20/300\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.1566 - val_loss: 0.1560\n",
      "Epoch 21/300\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.1553 - val_loss: 0.1554\n",
      "Epoch 22/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1540 - val_loss: 0.1543\n",
      "Epoch 23/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1531 - val_loss: 0.1525\n",
      "Epoch 24/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1520 - val_loss: 0.1515\n",
      "Epoch 25/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1509 - val_loss: 0.1511\n",
      "Epoch 26/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1500 - val_loss: 0.1496\n",
      "Epoch 27/300\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.1491 - val_loss: 0.1491\n",
      "Epoch 28/300\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.1481 - val_loss: 0.1473\n",
      "Epoch 29/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1470 - val_loss: 0.1467\n",
      "Epoch 30/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1463 - val_loss: 0.1457\n",
      "Epoch 31/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1453 - val_loss: 0.1447\n",
      "Epoch 32/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1446 - val_loss: 0.1449\n",
      "Epoch 33/300\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1435 - val_loss: 0.1433\n",
      "Epoch 34/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1431 - val_loss: 0.1429\n",
      "Epoch 35/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1424 - val_loss: 0.1424\n",
      "Epoch 36/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1418 - val_loss: 0.1415\n",
      "Epoch 37/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1413 - val_loss: 0.1410\n",
      "Epoch 38/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1408 - val_loss: 0.1405\n",
      "Epoch 39/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1403 - val_loss: 0.1401\n",
      "Epoch 40/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1398 - val_loss: 0.1396\n",
      "Epoch 41/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1394 - val_loss: 0.1395\n",
      "Epoch 42/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1390 - val_loss: 0.1389\n",
      "Epoch 43/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1386 - val_loss: 0.1385\n",
      "Epoch 44/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1382 - val_loss: 0.1381\n",
      "Epoch 45/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1379 - val_loss: 0.1380\n",
      "Epoch 46/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1376 - val_loss: 0.1378\n",
      "Epoch 47/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1372 - val_loss: 0.1371\n",
      "Epoch 48/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1368 - val_loss: 0.1372\n",
      "Epoch 49/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1366 - val_loss: 0.1374\n",
      "Epoch 50/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1364 - val_loss: 0.1366\n",
      "Epoch 51/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1360 - val_loss: 0.1361\n",
      "Epoch 52/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1357 - val_loss: 0.1357\n",
      "Epoch 53/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1354 - val_loss: 0.1356\n",
      "Epoch 54/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1352 - val_loss: 0.1354\n",
      "Epoch 55/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1349 - val_loss: 0.1352\n",
      "Epoch 56/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1349 - val_loss: 0.1349\n",
      "Epoch 57/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1343 - val_loss: 0.1345\n",
      "Epoch 58/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1342 - val_loss: 0.1349\n",
      "Epoch 59/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1338 - val_loss: 0.1340\n",
      "Epoch 60/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1336 - val_loss: 0.1336\n",
      "Epoch 61/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1334 - val_loss: 0.1338\n",
      "Epoch 62/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1333 - val_loss: 0.1334\n",
      "Epoch 63/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1330 - val_loss: 0.1331\n",
      "Epoch 64/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1327 - val_loss: 0.1333\n",
      "Epoch 65/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1325 - val_loss: 0.1331\n",
      "Epoch 66/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1325 - val_loss: 0.1328\n",
      "Epoch 67/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1321 - val_loss: 0.1322\n",
      "Epoch 68/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1320 - val_loss: 0.1323\n",
      "Epoch 69/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1316 - val_loss: 0.1318\n",
      "Epoch 70/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1314 - val_loss: 0.1320\n",
      "Epoch 71/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1313 - val_loss: 0.1315\n",
      "Epoch 72/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1311 - val_loss: 0.1312\n",
      "Epoch 73/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1309 - val_loss: 0.1312\n",
      "Epoch 74/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1307 - val_loss: 0.1309\n",
      "Epoch 75/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1305 - val_loss: 0.1307\n",
      "Epoch 76/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1304 - val_loss: 0.1306\n",
      "Epoch 77/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1302 - val_loss: 0.1303\n",
      "Epoch 78/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1300 - val_loss: 0.1303\n",
      "Epoch 79/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1298 - val_loss: 0.1301\n",
      "Epoch 80/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1296 - val_loss: 0.1299\n",
      "Epoch 81/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1296 - val_loss: 0.1297\n",
      "Epoch 82/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1293 - val_loss: 0.1297\n",
      "Epoch 83/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1292 - val_loss: 0.1296\n",
      "Epoch 84/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1289 - val_loss: 0.1296\n",
      "Epoch 85/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1288 - val_loss: 0.1290\n",
      "Epoch 86/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1287 - val_loss: 0.1296\n",
      "Epoch 87/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1285 - val_loss: 0.1291\n",
      "Epoch 88/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1283 - val_loss: 0.1288\n",
      "Epoch 89/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1282 - val_loss: 0.1284\n",
      "Epoch 90/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1281 - val_loss: 0.1283\n",
      "Epoch 91/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1279 - val_loss: 0.1285\n",
      "Epoch 92/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1277 - val_loss: 0.1280\n",
      "Epoch 93/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1276 - val_loss: 0.1279\n",
      "Epoch 94/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1274 - val_loss: 0.1279\n",
      "Epoch 95/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1273 - val_loss: 0.1278\n",
      "Epoch 96/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1272 - val_loss: 0.1278\n",
      "Epoch 97/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1271 - val_loss: 0.1275\n",
      "Epoch 98/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1269 - val_loss: 0.1280\n",
      "Epoch 99/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1268 - val_loss: 0.1273\n",
      "Epoch 100/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1267 - val_loss: 0.1270\n",
      "Epoch 101/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1265 - val_loss: 0.1267\n",
      "Epoch 102/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1264 - val_loss: 0.1269\n",
      "Epoch 103/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1262 - val_loss: 0.1265\n",
      "Epoch 104/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1261 - val_loss: 0.1264\n",
      "Epoch 105/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1260 - val_loss: 0.1266\n",
      "Epoch 106/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1259 - val_loss: 0.1263\n",
      "Epoch 107/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1258 - val_loss: 0.1264\n",
      "Epoch 108/300\n",
      "48000/48000 [==============================] - ETA: 0s - loss: 0.125 - 2s 51us/step - loss: 0.1256 - val_loss: 0.1258\n",
      "Epoch 109/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1255 - val_loss: 0.1260\n",
      "Epoch 110/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1254 - val_loss: 0.1258\n",
      "Epoch 111/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1253 - val_loss: 0.1258\n",
      "Epoch 112/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1252 - val_loss: 0.1259\n",
      "Epoch 113/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1251 - val_loss: 0.1255\n",
      "Epoch 114/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1249 - val_loss: 0.1253\n",
      "Epoch 115/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1249 - val_loss: 0.1255\n",
      "Epoch 116/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1247 - val_loss: 0.1255\n",
      "Epoch 117/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1246 - val_loss: 0.1249\n",
      "Epoch 118/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1245 - val_loss: 0.1249\n",
      "Epoch 119/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1244 - val_loss: 0.1253\n",
      "Epoch 120/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1244 - val_loss: 0.1249\n",
      "Epoch 121/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1242 - val_loss: 0.1247\n",
      "Epoch 122/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1242 - val_loss: 0.1248\n",
      "Epoch 123/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1240 - val_loss: 0.1245\n",
      "Epoch 124/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1239 - val_loss: 0.1242\n",
      "Epoch 125/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1238 - val_loss: 0.1242\n",
      "Epoch 126/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1237 - val_loss: 0.1243\n",
      "Epoch 127/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1235 - val_loss: 0.1242\n",
      "Epoch 128/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1235 - val_loss: 0.1241\n",
      "Epoch 129/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1234 - val_loss: 0.1237\n",
      "Epoch 130/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1233 - val_loss: 0.1241\n",
      "Epoch 131/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1231 - val_loss: 0.1240\n",
      "Epoch 132/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1231 - val_loss: 0.1235\n",
      "Epoch 133/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1230 - val_loss: 0.1234\n",
      "Epoch 134/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1230 - val_loss: 0.1234\n",
      "Epoch 135/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1228 - val_loss: 0.1234\n",
      "Epoch 136/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1226 - val_loss: 0.1232\n",
      "Epoch 137/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1226 - val_loss: 0.1229\n",
      "Epoch 138/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1225 - val_loss: 0.1228\n",
      "Epoch 139/300\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1223 - val_loss: 0.1226\n",
      "Epoch 140/300\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.1222 - val_loss: 0.1228\n",
      "Epoch 141/300\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.1221 - val_loss: 0.1225\n",
      "Epoch 142/300\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.1220 - val_loss: 0.1228\n",
      "Epoch 143/300\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.1219 - val_loss: 0.1221\n",
      "Epoch 144/300\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1217 - val_loss: 0.1219\n",
      "Epoch 145/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1216 - val_loss: 0.1219\n",
      "Epoch 146/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1215 - val_loss: 0.1218\n",
      "Epoch 147/300\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1213 - val_loss: 0.1218\n",
      "Epoch 148/300\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1213 - val_loss: 0.1215\n",
      "Epoch 149/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1211 - val_loss: 0.1222\n",
      "Epoch 150/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1211 - val_loss: 0.1215\n",
      "Epoch 151/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1208 - val_loss: 0.1214\n",
      "Epoch 152/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1208 - val_loss: 0.1213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1207 - val_loss: 0.1216\n",
      "Epoch 154/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1207 - val_loss: 0.1209\n",
      "Epoch 155/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1205 - val_loss: 0.1217\n",
      "Epoch 156/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1204 - val_loss: 0.1213\n",
      "Epoch 157/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1203 - val_loss: 0.1208\n",
      "Epoch 158/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1203 - val_loss: 0.1207\n",
      "Epoch 159/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1201 - val_loss: 0.1207\n",
      "Epoch 160/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1200 - val_loss: 0.1208\n",
      "Epoch 161/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1199 - val_loss: 0.1209\n",
      "Epoch 162/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1198 - val_loss: 0.1201\n",
      "Epoch 163/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1198 - val_loss: 0.1204\n",
      "Epoch 164/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1197 - val_loss: 0.1199\n",
      "Epoch 165/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1196 - val_loss: 0.1202\n",
      "Epoch 166/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1195 - val_loss: 0.1200\n",
      "Epoch 167/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1194 - val_loss: 0.1198\n",
      "Epoch 168/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1193 - val_loss: 0.1197\n",
      "Epoch 169/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1193 - val_loss: 0.1197\n",
      "Epoch 170/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1192 - val_loss: 0.1197\n",
      "Epoch 171/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1191 - val_loss: 0.1197\n",
      "Epoch 172/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1190 - val_loss: 0.1197\n",
      "Epoch 173/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1190 - val_loss: 0.1194\n",
      "Epoch 174/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1188 - val_loss: 0.1192\n",
      "Epoch 175/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1189 - val_loss: 0.1195\n",
      "Epoch 176/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1187 - val_loss: 0.1191\n",
      "Epoch 177/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1186 - val_loss: 0.1198\n",
      "Epoch 178/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1186 - val_loss: 0.1190\n",
      "Epoch 179/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1185 - val_loss: 0.1196\n",
      "Epoch 180/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1185 - val_loss: 0.1190\n",
      "Epoch 181/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1183 - val_loss: 0.1194\n",
      "Epoch 182/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1183 - val_loss: 0.1188\n",
      "Epoch 183/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1182 - val_loss: 0.1186\n",
      "Epoch 184/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1181 - val_loss: 0.1186\n",
      "Epoch 185/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1181 - val_loss: 0.1184\n",
      "Epoch 186/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1179 - val_loss: 0.1185\n",
      "Epoch 187/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1180 - val_loss: 0.1185\n",
      "Epoch 188/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1179 - val_loss: 0.1183\n",
      "Epoch 189/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1178 - val_loss: 0.1187\n",
      "Epoch 190/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1177 - val_loss: 0.1185\n",
      "Epoch 191/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1177 - val_loss: 0.1182\n",
      "Epoch 192/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1176 - val_loss: 0.1181\n",
      "Epoch 193/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1175 - val_loss: 0.1184\n",
      "Epoch 194/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1174 - val_loss: 0.1181\n",
      "Epoch 195/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1174 - val_loss: 0.1177\n",
      "Epoch 196/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1174 - val_loss: 0.1181\n",
      "Epoch 197/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1173 - val_loss: 0.1178\n",
      "Epoch 198/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1172 - val_loss: 0.1177\n",
      "Epoch 199/300\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.1171 - val_loss: 0.1175\n",
      "Epoch 200/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1171 - val_loss: 0.1179\n",
      "Epoch 201/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1170 - val_loss: 0.1176\n",
      "Epoch 202/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1170 - val_loss: 0.1177\n",
      "Epoch 203/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1169 - val_loss: 0.1175\n",
      "Epoch 204/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1169 - val_loss: 0.1174\n",
      "Epoch 205/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1168 - val_loss: 0.1174\n",
      "Epoch 206/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1167 - val_loss: 0.1173\n",
      "Epoch 207/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1166 - val_loss: 0.1175\n",
      "Epoch 208/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1167 - val_loss: 0.1174\n",
      "Epoch 209/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1166 - val_loss: 0.1171\n",
      "Epoch 210/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1165 - val_loss: 0.1169\n",
      "Epoch 211/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1165 - val_loss: 0.1169\n",
      "Epoch 212/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1164 - val_loss: 0.1174\n",
      "Epoch 213/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1164 - val_loss: 0.1174\n",
      "Epoch 214/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1162 - val_loss: 0.1167\n",
      "Epoch 215/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1163 - val_loss: 0.1170\n",
      "Epoch 216/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1162 - val_loss: 0.1168\n",
      "Epoch 217/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1161 - val_loss: 0.1167\n",
      "Epoch 218/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1160 - val_loss: 0.1168\n",
      "Epoch 219/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1160 - val_loss: 0.1166\n",
      "Epoch 220/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1160 - val_loss: 0.1166\n",
      "Epoch 221/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1159 - val_loss: 0.1166\n",
      "Epoch 222/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1158 - val_loss: 0.1161\n",
      "Epoch 223/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1158 - val_loss: 0.1164\n",
      "Epoch 224/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1158 - val_loss: 0.1167\n",
      "Epoch 225/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1157 - val_loss: 0.1165\n",
      "Epoch 226/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1157 - val_loss: 0.1161\n",
      "Epoch 227/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1156 - val_loss: 0.1163\n",
      "Epoch 228/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1156 - val_loss: 0.1160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1155 - val_loss: 0.1162\n",
      "Epoch 230/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1154 - val_loss: 0.1162\n",
      "Epoch 231/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1155 - val_loss: 0.1159\n",
      "Epoch 232/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1152 - val_loss: 0.1157\n",
      "Epoch 233/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1153 - val_loss: 0.1157\n",
      "Epoch 234/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1154 - val_loss: 0.1157\n",
      "Epoch 235/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1151 - val_loss: 0.1158\n",
      "Epoch 236/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1152 - val_loss: 0.1158\n",
      "Epoch 237/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1152 - val_loss: 0.1158\n",
      "Epoch 238/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1151 - val_loss: 0.1154\n",
      "Epoch 239/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1150 - val_loss: 0.1154\n",
      "Epoch 240/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1149 - val_loss: 0.1161\n",
      "Epoch 241/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1150 - val_loss: 0.1157\n",
      "Epoch 242/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1150 - val_loss: 0.1157\n",
      "Epoch 243/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1148 - val_loss: 0.1154\n",
      "Epoch 244/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1149 - val_loss: 0.1154\n",
      "Epoch 245/300\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1148 - val_loss: 0.1153\n",
      "Epoch 246/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1147 - val_loss: 0.1155\n",
      "Epoch 247/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1147 - val_loss: 0.1156\n",
      "Epoch 248/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1146 - val_loss: 0.1158\n",
      "Epoch 249/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1146 - val_loss: 0.1154\n",
      "Epoch 250/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1144 - val_loss: 0.1151\n",
      "Epoch 251/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1146 - val_loss: 0.1152\n",
      "Epoch 252/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1144 - val_loss: 0.1150\n",
      "Epoch 253/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1144 - val_loss: 0.1157\n",
      "Epoch 254/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1143 - val_loss: 0.1149\n",
      "Epoch 255/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1143 - val_loss: 0.1150\n",
      "Epoch 256/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1143 - val_loss: 0.1153\n",
      "Epoch 257/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1142 - val_loss: 0.1151\n",
      "Epoch 258/300\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1142 - val_loss: 0.1148\n",
      "Epoch 259/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1141 - val_loss: 0.1153\n",
      "Epoch 260/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1142 - val_loss: 0.1149\n",
      "Epoch 261/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1141 - val_loss: 0.1148\n",
      "Epoch 262/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1140 - val_loss: 0.1149\n",
      "Epoch 263/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1140 - val_loss: 0.1145\n",
      "Epoch 264/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1140 - val_loss: 0.1146\n",
      "Epoch 265/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1139 - val_loss: 0.1148\n",
      "Epoch 266/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1138 - val_loss: 0.1148\n",
      "Epoch 267/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1138 - val_loss: 0.1146\n",
      "Epoch 268/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1138 - val_loss: 0.1143\n",
      "Epoch 269/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1137 - val_loss: 0.1143\n",
      "Epoch 270/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1138 - val_loss: 0.1145\n",
      "Epoch 271/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1138 - val_loss: 0.1145\n",
      "Epoch 272/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1136 - val_loss: 0.1143\n",
      "Epoch 273/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1136 - val_loss: 0.1144\n",
      "Epoch 274/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1135 - val_loss: 0.1144\n",
      "Epoch 275/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1134 - val_loss: 0.1142\n",
      "Epoch 276/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1134 - val_loss: 0.1141\n",
      "Epoch 277/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1135 - val_loss: 0.1142\n",
      "Epoch 278/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1135 - val_loss: 0.1144\n",
      "Epoch 279/300\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1134 - val_loss: 0.1140\n",
      "Epoch 280/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1134 - val_loss: 0.1142\n",
      "Epoch 281/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1132 - val_loss: 0.1140\n",
      "Epoch 282/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1133 - val_loss: 0.1137\n",
      "Epoch 283/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1132 - val_loss: 0.1146\n",
      "Epoch 284/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1133 - val_loss: 0.1140\n",
      "Epoch 285/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1131 - val_loss: 0.1140\n",
      "Epoch 286/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1131 - val_loss: 0.1138\n",
      "Epoch 287/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1131 - val_loss: 0.1136\n",
      "Epoch 288/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1131 - val_loss: 0.1139\n",
      "Epoch 289/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1130 - val_loss: 0.1135\n",
      "Epoch 290/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1131 - val_loss: 0.1136\n",
      "Epoch 291/300\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1129 - val_loss: 0.1136\n",
      "Epoch 292/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1130 - val_loss: 0.1139\n",
      "Epoch 293/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1128 - val_loss: 0.1139\n",
      "Epoch 294/300\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1129 - val_loss: 0.1135\n",
      "Epoch 295/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1129 - val_loss: 0.1137\n",
      "Epoch 296/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1128 - val_loss: 0.1140\n",
      "Epoch 297/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1128 - val_loss: 0.1136\n",
      "Epoch 298/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1127 - val_loss: 0.1134\n",
      "Epoch 299/300\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1127 - val_loss: 0.1133\n",
      "Epoch 300/300\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1126 - val_loss: 0.1131\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x_train, x_train, epochs=300, batch_size = 256, shuffle = True,\n",
    "              validation_data = (x_val,x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss and validation split loss over the epochs\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig('sparseae_model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_imgs = autoencoder.predict(x_test)\n",
    "encoded_imgs = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/step\n",
      "Loss: 0.1066216037273407\n"
     ]
    }
   ],
   "source": [
    "evaluation = autoencoder.evaluate(x_test, x_test)\n",
    "\n",
    "print(\"Loss:\",evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66156393"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkingthe encode images mean\n",
    "encoded_imgs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting the original input vs reconstructed output\n",
    "n = 10\n",
    "plt.figure(figsize =(20,4))\n",
    "\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(2,n, i+1+n)\n",
    "    plt.imshow(reconstructed_imgs[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig('sparseae_output.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
