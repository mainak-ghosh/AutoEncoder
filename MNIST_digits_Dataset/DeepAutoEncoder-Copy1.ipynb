{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import History\n",
    "history = History()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Acuisition\n",
    "x_train=pd.read_csv(\"mnist_train.csv\")\n",
    "x_test=pd.read_csv(\"mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Visulization\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "y_train = x_train.iloc[:,1].values\n",
    "x_train = x_train.drop([\"label\"],axis=1)\n",
    "y_test = x_test.iloc[:,1].values\n",
    "x_test = x_test.drop([\"label\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val= train_test_split(x_train,y_train,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape = (48000, 784)\n",
      "x_test shape = (10000, 784)\n",
      "x_val shape = (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train shape = {x_train.shape}')\n",
    "print(f'x_test shape = {x_test.shape}')\n",
    "print(f'x_val shape = {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "\n",
    "\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "\n",
    "\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 784)               101136    \n",
      "=================================================================\n",
      "Total params: 222,384\n",
      "Trainable params: 222,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss = 'binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/200\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.3523 - val_loss: 0.2651\n",
      "Epoch 2/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.2607 - val_loss: 0.2561\n",
      "Epoch 3/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.2481 - val_loss: 0.2389\n",
      "Epoch 4/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.2281 - val_loss: 0.2193\n",
      "Epoch 5/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.2140 - val_loss: 0.2107\n",
      "Epoch 6/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.2057 - val_loss: 0.2010\n",
      "Epoch 7/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1982 - val_loss: 0.1962\n",
      "Epoch 8/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1930 - val_loss: 0.1905\n",
      "Epoch 9/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1865 - val_loss: 0.1820\n",
      "Epoch 10/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1789 - val_loss: 0.1754\n",
      "Epoch 11/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1731 - val_loss: 0.1737\n",
      "Epoch 12/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1683 - val_loss: 0.1660\n",
      "Epoch 13/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1642 - val_loss: 0.1631\n",
      "Epoch 14/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1611 - val_loss: 0.1602\n",
      "Epoch 15/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1584 - val_loss: 0.1569\n",
      "Epoch 16/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1562 - val_loss: 0.1543\n",
      "Epoch 17/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1540 - val_loss: 0.1529\n",
      "Epoch 18/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1520 - val_loss: 0.1525\n",
      "Epoch 19/200\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1499 - val_loss: 0.1493\n",
      "Epoch 20/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1477 - val_loss: 0.1464\n",
      "Epoch 21/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1456 - val_loss: 0.1450\n",
      "Epoch 22/200\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1436 - val_loss: 0.1422\n",
      "Epoch 23/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1417 - val_loss: 0.1408\n",
      "Epoch 24/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1402 - val_loss: 0.1402\n",
      "Epoch 25/200\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.1386 - val_loss: 0.1379\n",
      "Epoch 26/200\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.1373 - val_loss: 0.1358\n",
      "Epoch 27/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1360 - val_loss: 0.1357\n",
      "Epoch 28/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1350 - val_loss: 0.1341\n",
      "Epoch 29/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1339 - val_loss: 0.1342\n",
      "Epoch 30/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1327 - val_loss: 0.1313\n",
      "Epoch 31/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1313 - val_loss: 0.1318\n",
      "Epoch 32/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1303 - val_loss: 0.1316\n",
      "Epoch 33/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1293 - val_loss: 0.1288\n",
      "Epoch 34/200\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1282 - val_loss: 0.1282\n",
      "Epoch 35/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1273 - val_loss: 0.1286\n",
      "Epoch 36/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1264 - val_loss: 0.1265\n",
      "Epoch 37/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1256 - val_loss: 0.1257\n",
      "Epoch 38/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1247 - val_loss: 0.1245\n",
      "Epoch 39/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1239 - val_loss: 0.1234\n",
      "Epoch 40/200\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.1233 - val_loss: 0.1240\n",
      "Epoch 41/200\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.1226 - val_loss: 0.1223\n",
      "Epoch 42/200\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.1220 - val_loss: 0.1218\n",
      "Epoch 43/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1213 - val_loss: 0.1209\n",
      "Epoch 44/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1209 - val_loss: 0.1228\n",
      "Epoch 45/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1203 - val_loss: 0.1206\n",
      "Epoch 46/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1198 - val_loss: 0.1215\n",
      "Epoch 47/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1194 - val_loss: 0.1192\n",
      "Epoch 48/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1188 - val_loss: 0.1197\n",
      "Epoch 49/200\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.1184 - val_loss: 0.1184\n",
      "Epoch 50/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1180 - val_loss: 0.1177\n",
      "Epoch 51/200\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1175 - val_loss: 0.1175\n",
      "Epoch 52/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1171 - val_loss: 0.1168\n",
      "Epoch 53/200\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.1167 - val_loss: 0.1157\n",
      "Epoch 54/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1162 - val_loss: 0.1162\n",
      "Epoch 55/200\n",
      "48000/48000 [==============================] - 2s 48us/step - loss: 0.1160 - val_loss: 0.1171\n",
      "Epoch 56/200\n",
      "48000/48000 [==============================] - 2s 48us/step - loss: 0.1155 - val_loss: 0.1152\n",
      "Epoch 57/200\n",
      "48000/48000 [==============================] - 2s 48us/step - loss: 0.1152 - val_loss: 0.1161\n",
      "Epoch 58/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1148 - val_loss: 0.1146\n",
      "Epoch 59/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1145 - val_loss: 0.1155\n",
      "Epoch 60/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1141 - val_loss: 0.1141\n",
      "Epoch 61/200\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1138 - val_loss: 0.1149\n",
      "Epoch 62/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1135 - val_loss: 0.1155\n",
      "Epoch 63/200\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.1131 - val_loss: 0.1147\n",
      "Epoch 64/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1127 - val_loss: 0.1132\n",
      "Epoch 65/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1125 - val_loss: 0.1124\n",
      "Epoch 66/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.1121 - val_loss: 0.1138\n",
      "Epoch 67/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1118 - val_loss: 0.1129\n",
      "Epoch 68/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1116 - val_loss: 0.1134\n",
      "Epoch 69/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1111 - val_loss: 0.1134\n",
      "Epoch 70/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1110 - val_loss: 0.1112\n",
      "Epoch 71/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1106 - val_loss: 0.1104\n",
      "Epoch 72/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1102 - val_loss: 0.1110\n",
      "Epoch 73/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1100 - val_loss: 0.1111\n",
      "Epoch 74/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1096 - val_loss: 0.1094\n",
      "Epoch 75/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1094 - val_loss: 0.1097\n",
      "Epoch 76/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1091 - val_loss: 0.1097\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.1087 - val_loss: 0.1104\n",
      "Epoch 78/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1085 - val_loss: 0.1087\n",
      "Epoch 79/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1082 - val_loss: 0.1104\n",
      "Epoch 80/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1078 - val_loss: 0.1075\n",
      "Epoch 81/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1074 - val_loss: 0.1068\n",
      "Epoch 82/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1073 - val_loss: 0.1084\n",
      "Epoch 83/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1069 - val_loss: 0.1061\n",
      "Epoch 84/200\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.1068 - val_loss: 0.1074\n",
      "Epoch 85/200\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.1065 - val_loss: 0.1069\n",
      "Epoch 86/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1060 - val_loss: 0.1061\n",
      "Epoch 87/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1061 - val_loss: 0.1074\n",
      "Epoch 88/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1058 - val_loss: 0.1057\n",
      "Epoch 89/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1054 - val_loss: 0.1062\n",
      "Epoch 90/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1052 - val_loss: 0.1081\n",
      "Epoch 91/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1051 - val_loss: 0.1067\n",
      "Epoch 92/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1049 - val_loss: 0.1058\n",
      "Epoch 93/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1047 - val_loss: 0.1057\n",
      "Epoch 94/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1046 - val_loss: 0.1055\n",
      "Epoch 95/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1043 - val_loss: 0.1062\n",
      "Epoch 96/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1042 - val_loss: 0.1049\n",
      "Epoch 97/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1040 - val_loss: 0.1048\n",
      "Epoch 98/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1039 - val_loss: 0.1031\n",
      "Epoch 99/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1036 - val_loss: 0.1052\n",
      "Epoch 100/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1035 - val_loss: 0.1051\n",
      "Epoch 101/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1032 - val_loss: 0.1069\n",
      "Epoch 102/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1031 - val_loss: 0.1046\n",
      "Epoch 103/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1030 - val_loss: 0.1049\n",
      "Epoch 104/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1027 - val_loss: 0.1044\n",
      "Epoch 105/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1026 - val_loss: 0.1047\n",
      "Epoch 106/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1026 - val_loss: 0.1023\n",
      "Epoch 107/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1024 - val_loss: 0.1044\n",
      "Epoch 108/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1022 - val_loss: 0.1051\n",
      "Epoch 109/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1021 - val_loss: 0.1020\n",
      "Epoch 110/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1019 - val_loss: 0.1046\n",
      "Epoch 111/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1018 - val_loss: 0.1027\n",
      "Epoch 112/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1016 - val_loss: 0.1020\n",
      "Epoch 113/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1013 - val_loss: 0.1036\n",
      "Epoch 114/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1014 - val_loss: 0.1026\n",
      "Epoch 115/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1011 - val_loss: 0.1015\n",
      "Epoch 116/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1009 - val_loss: 0.1016\n",
      "Epoch 117/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1009 - val_loss: 0.1018\n",
      "Epoch 118/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1006 - val_loss: 0.1012\n",
      "Epoch 119/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1005 - val_loss: 0.1003\n",
      "Epoch 120/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.1004 - val_loss: 0.1005\n",
      "Epoch 121/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1003 - val_loss: 0.1005\n",
      "Epoch 122/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1001 - val_loss: 0.1025\n",
      "Epoch 123/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.1001 - val_loss: 0.0996\n",
      "Epoch 124/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.1000 - val_loss: 0.1005\n",
      "Epoch 125/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.0998 - val_loss: 0.1015\n",
      "Epoch 126/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.0997 - val_loss: 0.0997\n",
      "Epoch 127/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0995 - val_loss: 0.1005\n",
      "Epoch 128/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0994 - val_loss: 0.1003\n",
      "Epoch 129/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0995 - val_loss: 0.0999\n",
      "Epoch 130/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.0992 - val_loss: 0.0997\n",
      "Epoch 131/200\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.0991 - val_loss: 0.1013\n",
      "Epoch 132/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0991 - val_loss: 0.1003\n",
      "Epoch 133/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0990 - val_loss: 0.0994\n",
      "Epoch 134/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0989 - val_loss: 0.0991\n",
      "Epoch 135/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0987 - val_loss: 0.1007\n",
      "Epoch 136/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0987 - val_loss: 0.0990\n",
      "Epoch 137/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0986 - val_loss: 0.1000\n",
      "Epoch 138/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0984 - val_loss: 0.0989\n",
      "Epoch 139/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0983 - val_loss: 0.1017\n",
      "Epoch 140/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0984 - val_loss: 0.0985\n",
      "Epoch 141/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0982 - val_loss: 0.0992\n",
      "Epoch 142/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0981 - val_loss: 0.0988\n",
      "Epoch 143/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0980 - val_loss: 0.0987\n",
      "Epoch 144/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0980 - val_loss: 0.0986\n",
      "Epoch 145/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0978 - val_loss: 0.1000\n",
      "Epoch 146/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0977 - val_loss: 0.0986\n",
      "Epoch 147/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0976 - val_loss: 0.0976\n",
      "Epoch 148/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.0976 - val_loss: 0.0983\n",
      "Epoch 149/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0975 - val_loss: 0.0987\n",
      "Epoch 150/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.0974 - val_loss: 0.0974\n",
      "Epoch 151/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0974 - val_loss: 0.0994\n",
      "Epoch 152/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0972 - val_loss: 0.0998\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0973 - val_loss: 0.0987\n",
      "Epoch 154/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.0970 - val_loss: 0.0988\n",
      "Epoch 155/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.0970 - val_loss: 0.0977\n",
      "Epoch 156/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.0969 - val_loss: 0.0995\n",
      "Epoch 157/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0969 - val_loss: 0.0983\n",
      "Epoch 158/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.0968 - val_loss: 0.0993\n",
      "Epoch 159/200\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.0967 - val_loss: 0.0983\n",
      "Epoch 160/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0967 - val_loss: 0.0973\n",
      "Epoch 161/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0966 - val_loss: 0.0982\n",
      "Epoch 162/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0964 - val_loss: 0.0967\n",
      "Epoch 163/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0963 - val_loss: 0.0960\n",
      "Epoch 164/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0963 - val_loss: 0.0960\n",
      "Epoch 165/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0962 - val_loss: 0.0976\n",
      "Epoch 166/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0962 - val_loss: 0.0963\n",
      "Epoch 167/200\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0961 - val_loss: 0.0959\n",
      "Epoch 168/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0960 - val_loss: 0.0964\n",
      "Epoch 169/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0958 - val_loss: 0.0981\n",
      "Epoch 170/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0958 - val_loss: 0.0970\n",
      "Epoch 171/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0958 - val_loss: 0.0988\n",
      "Epoch 172/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0959 - val_loss: 0.0963\n",
      "Epoch 173/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0957 - val_loss: 0.0986\n",
      "Epoch 174/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0956 - val_loss: 0.0971\n",
      "Epoch 175/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0956 - val_loss: 0.0964\n",
      "Epoch 176/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0953 - val_loss: 0.0959\n",
      "Epoch 177/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0954 - val_loss: 0.0953\n",
      "Epoch 178/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0954 - val_loss: 0.0973\n",
      "Epoch 179/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0952 - val_loss: 0.0967\n",
      "Epoch 180/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0953 - val_loss: 0.0953\n",
      "Epoch 181/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0951 - val_loss: 0.0964\n",
      "Epoch 182/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0950 - val_loss: 0.0962\n",
      "Epoch 183/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0950 - val_loss: 0.0950\n",
      "Epoch 184/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0949 - val_loss: 0.0951\n",
      "Epoch 185/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0948 - val_loss: 0.0961\n",
      "Epoch 186/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0949 - val_loss: 0.0952\n",
      "Epoch 187/200\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0947 - val_loss: 0.0946\n",
      "Epoch 188/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0947 - val_loss: 0.0969\n",
      "Epoch 189/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0947 - val_loss: 0.0968\n",
      "Epoch 190/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0945 - val_loss: 0.0975\n",
      "Epoch 191/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0946 - val_loss: 0.0963\n",
      "Epoch 192/200\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0944 - val_loss: 0.0950\n",
      "Epoch 193/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0943 - val_loss: 0.0963\n",
      "Epoch 194/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0943 - val_loss: 0.0955\n",
      "Epoch 195/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0943 - val_loss: 0.0956\n",
      "Epoch 196/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0942 - val_loss: 0.0947\n",
      "Epoch 197/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0941 - val_loss: 0.0968\n",
      "Epoch 198/200\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0941 - val_loss: 0.0940\n",
      "Epoch 199/200\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.0941 - val_loss: 0.0941\n",
      "Epoch 200/200\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.0939 - val_loss: 0.0948\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(x_train, x_train, epochs=200, batch_size = 256, shuffle = True,\n",
    "              validation_data = (x_val,x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training loss and validation split loss over the epochs\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig('deepae_model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_imgs = autoencoder.predict(x_test)\n",
    "encoded_imgs = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/step\n",
      "Loss: 0.09343327107429504\n"
     ]
    }
   ],
   "source": [
    "evaluation = autoencoder.evaluate(x_test, x_test)\n",
    "print(\"Loss:\",evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1127315"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkingthe encode images mean\n",
    "encoded_imgs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting the original input vs reconstructed output\n",
    "n = 10\n",
    "plt.figure(figsize =(20,4))\n",
    "\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(reconstructed_imgs[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig('deepae_output.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
